{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f89f27c-ca74-47ef-b2e6-50c0ef405969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03d9bd-dc33-4b9a-96d5-fdd83b587295",
   "metadata": {},
   "source": [
    "# get data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5707bf47-3cc5-4188-b4f5-f14174461bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nda = dj.create_virtual_module('microns_phase3_nda','microns_phase3_nda')\n",
    "radtune = dj.create_virtual_module('pipeline_radtune', 'pipeline_radtune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e9f12-8769-4535-9549-f84816c6c0fd",
   "metadata": {},
   "source": [
    "# get tuned responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf63d87-0fee-446a-8d7a-76982ce4edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_avg(unit_key, inter_trial_begin=(15/16-.5)/2, inter_trial_end=(15/16-.5)/2):\n",
    "    '''\n",
    "    return sorted directions and trial mean responses\n",
    "    '''\n",
    "    trace, frame_times, ms_delay = ((nda.Activity & unit_key) * nda.ScanTimes * nda.ScanUnit).fetch1('trace', 'frame_times', 'ms_delay')\n",
    "    f2a = interp1d(frame_times+ms_delay/1000,trace)  # interpolate from frame times to activity\n",
    "\n",
    "    trials = pd.DataFrame(\n",
    "        (nda.Trial * nda.Monet2 & unit_key).fetch('onsets','directions', 'start_frame_time', 'end_frame_time',as_dict=True)\n",
    "    )\n",
    "\n",
    "    trials['dir_time_bin'] = trials.apply(\n",
    "        axis=1, \n",
    "        func=lambda trial : np.append((np.array(trial.onsets).ravel() + trial.start_frame_time), trial.end_frame_time)\n",
    "    )  # add start time to onsets and append the end frame time\n",
    "    trials['directions'] = trials.directions.apply(lambda d : np.array(d).ravel())\n",
    "\n",
    "    ca_frame_hz = 6.3\n",
    "\n",
    "    # QC: make sure all the resampled directions have the same amount of bins\n",
    "    qc_trial_time_diff = trials.dir_time_bin.apply(\n",
    "        func={\n",
    "            'length_diff_range':lambda t : np.ptp(np.diff(t)),\n",
    "            'min_length':lambda t : np.min(np.diff(t)),\n",
    "            'max_length':lambda t : np.max(np.diff(t)),\n",
    "        }, \n",
    "    ).to_frame().reset_index(names=['stats', 'trial']).pivot(columns='stats', values='dir_time_bin', index='trial')\n",
    "    qc_trial_time_diff = qc_trial_time_diff.assign(\n",
    "        min_bins=((qc_trial_time_diff.min_length - inter_trial_begin - inter_trial_end) * ca_frame_hz).astype(int),\n",
    "        max_bins=((qc_trial_time_diff.max_length - inter_trial_begin - inter_trial_end) * ca_frame_hz).astype(int),\n",
    "    )\n",
    "    if len(np.unique(np.c_[qc_trial_time_diff.min_bins.to_numpy(), qc_trial_time_diff.max_bins.to_numpy()])) != 1:\n",
    "        print('QC: subtrial length differences')\n",
    "        display(qc_trial_time_diff.head())\n",
    "        raise ValueError('trial length variation led to difference in number of resampled points!')\n",
    "    n_resampled_bins = int(qc_trial_time_diff.min_bins.unique()) + 1\n",
    "\n",
    "\n",
    "    # resample responses at ca imaging frame rate\n",
    "    sorted_dirs = np.sort((np.unique(np.stack(trials.directions.to_numpy()))))\n",
    "    responses = np.full([len(trials), len(sorted_dirs), n_resampled_bins], np.nan)  # trial x dir x time bin\n",
    "    for i, trial in enumerate(trials.itertuples()):\n",
    "        assert (sorted_dirs == np.sort(trial.directions)).all()\n",
    "        for _dir, start, end in zip(trial.directions, trial.dir_time_bin[:-1], trial.dir_time_bin[1:]):\n",
    "            j = (sorted_dirs == _dir).nonzero()[0][0]\n",
    "            sampling_time = np.arange(start + inter_trial_begin, end - inter_trial_end, 1 / ca_frame_hz)\n",
    "            assert len(sampling_time) == n_resampled_bins\n",
    "            responses[i, j] = f2a(sampling_time)\n",
    "    assert not np.isnan(responses).any()\n",
    "    responses = responses.mean(axis=0)  # trial average\n",
    "    return sorted_dirs, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3dfa017-20af-44a1-b0e7-64d9b8938535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:09,  8.24it/s]\n"
     ]
    }
   ],
   "source": [
    "key_limit = 5\n",
    "inter_trial_begin = (15/16-.5)/2 # time to skip at beginning of subtrial (sec)\n",
    "inter_trial_end = (15/16-.5)/2 # time to skip at the end of subtrials (sec)\n",
    "t_edges = np.linspace(0,2*np.pi,17)-np.pi/16\n",
    "von_keys = []\n",
    "for i in range(16):\n",
    "    bin_center = (((t_edges[i+1] - t_edges[i]) / 2) + t_edges[i])\n",
    "    von_rest = f'pref_theta > {t_edges[i]} and pref_theta < {t_edges[i+1]}'\n",
    "    von_rel = (radtune.VonFit.Unit & {'animal_id':17797, 'vonfit_method':3, 'ori_type':\"dir\"} & \n",
    "               nda.ScanInclude() & von_rest)\n",
    "    pref_thetas, keys = von_rel.fetch('pref_theta', 'KEY', order_by='von_pred_adv DESC',limit=key_limit)\n",
    "    [k.update({'pref_theta': p * 180/np.pi, 'bin': bin_center * 180/np.pi}) for p,k in zip(pref_thetas, keys)];\n",
    "    von_keys.extend(keys)\n",
    "von_keys = pd.DataFrame(von_keys).sort_values('pref_theta')\n",
    "\n",
    "# get trial average responses\n",
    "sorted_dirs = np.sort((nda.Trial * nda.Monet2 & von_keys).fetch('directions', limit=1)[0])\n",
    "responses = []  # list of dir x time bin arrays\n",
    "for _, unit_key in tqdm(von_keys.iterrows()):\n",
    "    _dirs, _responses = get_trial_avg(dict(unit_key), inter_trial_begin, inter_trial_end)\n",
    "    assert (_dirs == sorted_dirs).all()\n",
    "    responses.append(_responses)\n",
    "\n",
    "responses = np.stack(responses, axis=0)  # neuron x dir x time bin\n",
    "responses = np.reshape(responses, [len(responses), -1])  # neuron x time bin\n",
    "# independently normalize each neuron by the min and max\n",
    "responses -= np.min(responses,axis=1,keepdims=True)\n",
    "responses /= np.max(responses,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280d18e-7ad9-4bb0-bb38-17f6761ee5b7",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a181d346-dcbe-4b8a-82ff-0d1a2641f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('directions.npy', sorted_dirs)\n",
    "von_keys.to_pickle('tuned_units.pkl')\n",
    "np.save('tuned_unit_responses.npy', responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
